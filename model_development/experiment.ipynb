{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159ce603",
   "metadata": {},
   "source": [
    "# DO NOT USE, DEBUG ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e895dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "from torch.utils.data import DataLoader\n",
    "from data.dataset import WeedDataset\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d25545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to optimized model\n",
    "MODEL_PATH = 'optimized_models/model_quantized.onnx'  # Use quantized ONNX model\n",
    "DATA_PATH = 'data'  # Path to data directory\n",
    "BATCH_SIZE = 32\n",
    "    \n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"Model file {MODEL_PATH} not found. Please run convert_model.py first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625a97c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation dataset...\n",
      "Validation dataset size: 169 images\n",
      "Class distribution: {0: 102, 1: 67}\n"
     ]
    }
   ],
   "source": [
    "# Create validation dataset and dataloader\n",
    "print(\"Loading validation dataset...\")\n",
    "val_dataset = WeedDataset(DATA_PATH, split='val')\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Validation dataset size: {len(val_dataset)} images\")\n",
    "class_dist = val_dataset.get_class_distribution()\n",
    "print(f\"Class distribution: {class_dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f615b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONNX model from optimized_models/model_quantized.onnx...\n"
     ]
    },
    {
     "ename": "NotImplemented",
     "evalue": "[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for ConvInteger(10) node with name '/backbone/stem/net/net.0/Conv_quant'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplemented\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize ONNX Runtime session\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading ONNX model from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[43monnxruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m input_name \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget_inputs()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\Nathan\\anaconda3\\envs\\weed-detection\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:419\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[1;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[1;32mc:\\Users\\Nathan\\anaconda3\\envs\\weed-detection\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:491\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[1;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[0;32m    488\u001b[0m     disabled_optimizers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(disabled_optimizers)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# initialize the C++ InferenceSession\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess \u001b[38;5;241m=\u001b[39m sess\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess\u001b[38;5;241m.\u001b[39msession_options\n",
      "\u001b[1;31mNotImplemented\u001b[0m: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for ConvInteger(10) node with name '/backbone/stem/net/net.0/Conv_quant'"
     ]
    }
   ],
   "source": [
    "# class names mapping\n",
    "class_names = {0: 'Broadleaf', 1: 'Grass'}\n",
    "\n",
    "# init ONNX Runtime session\n",
    "print(f\"Loading ONNX model from {MODEL_PATH}...\")\n",
    "session = onnxruntime.InferenceSession(MODEL_PATH)\n",
    "input_name = session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85cf300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the optimized ONNX model on validation dataset\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "from torch.utils.data import DataLoader\n",
    "from data.dataset import WeedDataset\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Path to optimized model\n",
    "MODEL_PATH = 'optimized_models/model_quantized.onnx'  # Use quantized ONNX model\n",
    "DATA_PATH = 'data'  # Path to data directory\n",
    "BATCH_SIZE = 32\n",
    "    \n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"Model file {MODEL_PATH} not found. Please run convert_model.py first.\")\n",
    "\n",
    "# Create validation dataset and dataloader\n",
    "print(\"Loading validation dataset...\")\n",
    "val_dataset = WeedDataset(DATA_PATH, split='val')\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Validation dataset size: {len(val_dataset)} images\")\n",
    "class_dist = val_dataset.get_class_distribution()\n",
    "print(f\"Class distribution: {class_dist}\")\n",
    "\n",
    "# Class names mapping\n",
    "class_names = {0: 'Broadleaf', 1: 'Grass'}\n",
    "\n",
    "# Initialize ONNX Runtime session\n",
    "print(f\"Loading ONNX model from {MODEL_PATH}...\")\n",
    "session = onnxruntime.InferenceSession(MODEL_PATH)\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "# Function to run inference\n",
    "def onnx_inference(session, input_data):\n",
    "    ort_inputs = {input_name: input_data}\n",
    "    ort_outputs = session.run(None, ort_inputs)\n",
    "    return ort_outputs[0]\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model():\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    inference_times = []\n",
    "    \n",
    "    print(\"Evaluating model on validation set...\")\n",
    "    for images, labels in tqdm(val_loader):\n",
    "        # Convert to numpy for ONNX Runtime\n",
    "        input_data = images.numpy()\n",
    "        \n",
    "        # Run inference and measure time\n",
    "        start_time = time.time()\n",
    "        outputs = onnx_inference(session, input_data)\n",
    "        inference_time = (time.time() - start_time) * 1000  # ms\n",
    "        inference_times.append(inference_time)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = np.argmax(outputs, axis=1)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        correct = (predictions == labels.numpy()).sum()\n",
    "        total_correct += correct\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    \n",
    "    return accuracy, avg_inference_time, all_predictions, all_labels\n",
    "\n",
    "# Run evaluation\n",
    "accuracy, avg_inference_time, predictions, labels = evaluate_model()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n===== Model Evaluation Results =====\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Average Inference Time: {avg_inference_time:.2f} ms per batch\")\n",
    "print(f\"Average Inference Time: {avg_inference_time/BATCH_SIZE:.2f} ms per image\")\n",
    "print(f\"Throughput: {1000/(avg_inference_time/BATCH_SIZE):.1f} images/second\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[class_names[i] for i in range(len(class_names))],\n",
    "            yticklabels=[class_names[i] for i in range(len(class_names))])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(\n",
    "    labels, predictions, \n",
    "    target_names=[class_names[i] for i in range(len(class_names))],\n",
    "    digits=3\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Compare with original PyTorch model accuracy (if available)\n",
    "try:\n",
    "    from models.tinyresvit import TinyResViT\n",
    "    from utils import accuracy as acc_metric\n",
    "    \n",
    "    print(\"\\nComparing with original PyTorch model...\")\n",
    "    original_model = TinyResViT(num_classes=2)\n",
    "    checkpoint = torch.load('full_training/run_20250503_045116/best_model.pth', map_location='cpu')\n",
    "    \n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        original_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        original_model.load_state_dict(checkpoint)\n",
    "        \n",
    "    original_model.eval()\n",
    "    \n",
    "    # Evaluate original PyTorch model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            outputs = original_model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    pytorch_acc = correct / total\n",
    "    print(f\"Original PyTorch Model Accuracy: {pytorch_acc:.4f} ({pytorch_acc*100:.2f}%)\")\n",
    "    print(f\"Accuracy difference: {(pytorch_acc - accuracy)*100:.2f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not load original PyTorch model for comparison: {e}\")\n",
    "\n",
    "# Generate per-class metrics\n",
    "print(\"\\nPer-class Performance:\")\n",
    "for class_idx, class_name in class_names.items():\n",
    "    class_mask = np.array(labels) == class_idx\n",
    "    class_correct = np.sum((np.array(predictions) == class_idx) & class_mask)\n",
    "    class_total = np.sum(class_mask)\n",
    "    class_acc = class_correct / class_total if class_total > 0 else 0\n",
    "    print(f\"{class_name}: {class_acc:.4f} ({class_correct}/{class_total})\")\n",
    "    \n",
    "# Display some example predictions\n",
    "def show_predictions(num_samples=5):\n",
    "    # Reset the dataloader\n",
    "    val_dataset_vis = WeedDataset(DATA_PATH, split='val')\n",
    "    val_loader_vis = DataLoader(val_dataset_vis, batch_size=1, shuffle=True)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3*num_samples))\n",
    "    \n",
    "    for i, (image, label) in enumerate(val_loader_vis):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "            \n",
    "        # Get prediction\n",
    "        input_data = image.numpy()\n",
    "        output = onnx_inference(session, input_data)\n",
    "        pred = np.argmax(output, axis=1)[0]\n",
    "        \n",
    "        # Convert image for display\n",
    "        img = image.squeeze(0)\n",
    "        # Denormalize\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n",
    "        img = img * std + mean\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Plot\n",
    "        plt.subplot(num_samples, 1, i+1)\n",
    "        plt.imshow(img)\n",
    "        true_label = class_names[label.item()]\n",
    "        pred_label = class_names[pred]\n",
    "        color = 'green' if pred == label.item() else 'red'\n",
    "        plt.title(f\"True: {true_label}, Predicted: {pred_label}\", color=color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show some example predictions\n",
    "show_predictions(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbf3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weed-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
